# Email Accounts Dashboard Audit Report
**Date:** October 20, 2025
**Auditor:** Claude Code
**Dashboard:** Email Accounts Infrastructure Dashboard

---

## Executive Summary

This audit examined the email accounts section of the dashboard to diagnose why the **total number of email accounts** and **number of email accounts per client** displayed may not be accurate and up-to-date.

### Key Findings:
1. ‚úÖ **Data Flow Architecture is Sound** - The system uses a well-designed real-time database query approach
2. ‚ö†Ô∏è **Deduplication Logic Changed Recently** - Per-workspace deduplication was implemented to fix overcounting
3. ‚ö†Ô∏è **60-Minute Cache on Infrastructure Data** - May show stale data for up to 1 hour
4. ‚ö†Ô∏è **Database Access Limitations** - The `sender_emails_cache` table is not accessible with anon key
5. ‚úÖ **Manual Refresh Available** - Users can force-refresh to get latest data

---

## System Architecture Overview

### Data Flow

```
Email Bison API (External)
    ‚Üì (Nightly sync via poll-sender-emails cron)
sender_emails_cache table (Supabase)
    ‚Üì (Real-time query with 60-min cache)
realtimeDataService.ts ‚Üí fetchInfrastructureDataRealtime()
    ‚Üì (Transformation)
fieldMappings.ts ‚Üí transformToEmailAccount()
    ‚Üì (Deduplication by email+workspace)
realtimeDataService.ts (lines 383-405)
    ‚Üì (Context state)
DashboardContext.tsx ‚Üí infrastructureDashboard.emailAccounts
    ‚Üì (UI calculations)
EmailAccountsPage.tsx (lines 822-870)
    ‚Üì (Display)
Dashboard Cards showing totals
```

### Key Files
- **Data Service:** `/src/services/realtimeDataService.ts` (lines 331-460)
- **Field Mappings:** `/src/lib/fieldMappings.ts` (lines 176-205)
- **UI Component:** `/src/pages/EmailAccountsPage.tsx` (lines 822-870, 1073-1127)
- **Context:** `/src/contexts/DashboardContext.tsx` (lines 298-316, 513-617)

---

## Detailed Analysis

### 1. Data Source: `sender_emails_cache` Table

**Location:** Supabase database
**Update Frequency:** Nightly via `poll-sender-emails` cron job (midnight)
**Purpose:** Cache of all email accounts from Email Bison API

**Access Pattern:**
```typescript
// realtimeDataService.ts:346-351
const { data: accounts, error } = await supabase
  .from('sender_emails_cache')
  .select('*')
  .order('last_synced_at', { ascending: false })
  .limit(totalCount || 10000); // Explicit limit to bypass 1000-row default
```

**‚ö†Ô∏è Issue Identified:**
- Default Supabase limit is 1000 rows
- Code explicitly sets `limit(totalCount || 10000)` to fetch ALL accounts
- If table has > 10,000 accounts, data will be truncated
- **Recommendation:** Use pagination or remove limit entirely

### 2. Field Transformation: `transformToEmailAccount()`

**Location:** [fieldMappings.ts:176-205](src/lib/fieldMappings.ts#L176-L205)

The transformation maps database columns to the expected UI field structure:

```typescript
{
  id: dbRow.id,
  workspace_name: dbRow.workspace_name,
  fields: {
    'Email': dbRow.email_address,
    'Status': dbRow.status,
    'Client Name (from Client)': [dbRow.workspace_name],
    'Price': dbRow.price || 0,
    'Daily Limit': dbRow.daily_limit || 0,
    // ... more fields
  }
}
```

**‚úÖ No Issues Found** - Transformation is straightforward and correct.

### 3. Deduplication Logic: **CRITICAL FINDING**

**Location:** [realtimeDataService.ts:383-405](src/services/realtimeDataService.ts#L383-L405)

**Current Implementation (After Recent Fix):**
```typescript
// CRITICAL FIX: Deduplicate by (email_address + workspace_name) instead of just email_address
const deduplicatedData: any[] = [];
const seenEmailWorkspace = new Set<string>();

for (const account of transformedData) {
  const email = account.fields['Email'] || account.fields['Email Account'];
  const workspace = account.fields['Client Name (from Client)']?.[0] || account.workspace_name;
  const key = `${email}|${workspace}`; // ‚¨ÖÔ∏è Composite key!

  if (email && !seenEmailWorkspace.has(key)) {
    seenEmailWorkspace.add(key);
    deduplicatedData.push(account);
  }
}
```

**Why This Matters:**
- **Before fix:** Deduplication was GLOBAL (by email only) - caused undercounting
- **After fix:** Deduplication is PER-WORKSPACE - allows same email to appear for different clients
- **Git history shows:** Recent commit `bbbb502` - "Change deduplication from global to per-workspace"

**Example Scenario:**
```
Email: john@example.com
Client A: 1 account
Client B: 1 account (different bison_instance)

OLD BEHAVIOR (global dedup):
  - Total shown: 1 account
  - WRONG: Client B's account was hidden

NEW BEHAVIOR (per-workspace dedup):
  - Total shown: 2 accounts
  - CORRECT: Both clients see their accounts
```

**‚ö†Ô∏è Potential Issue:**
If the same email+workspace appears in MULTIPLE bison instances (e.g., "maverick" and "email"):
- Only ONE will be counted (first by `last_synced_at` DESC)
- This is INTENTIONAL - it's the same account in different systems
- However, if truly separate accounts, this could cause undercounting

### 4. Dashboard Metrics Calculation

**Location:** [EmailAccountsPage.tsx:822-870](src/pages/EmailAccountsPage.tsx#L822-L870)

**Calculation Logic:**
```typescript
// Total accounts
const totalAccounts = accounts.length;

// Unique clients
const uniqueClients = new Set(
  accounts.map(account => {
    const clientField = account.fields['Client'];
    return clientField && clientField.length > 0 ? clientField[0] : 'Unknown';
  })
).size;

// Average per client
const avgAccountsPerClient = uniqueClients > 0
  ? (totalAccounts / uniqueClients).toFixed(1)
  : '0';
```

**‚úÖ Logic is Correct** - Simple and accurate calculation.

**Displayed Metrics:**
1. **Total Email Accounts:** `accountStats.total` (line 1073)
2. **Avg per Client:** `accountStats.avgPerClient` (line 1089)
3. **Connected:** `accountStats.connected` (line 1289)
4. **Disconnected:** `accountStats.disconnected` (line 1296)

### 5. Caching Behavior: **IMPORTANT**

**Cache Configuration:** [dataService.ts:34-39](src/services/dataService.ts#L34-L39)
```typescript
const CACHE_TTL = {
  KPI: 2 * 60 * 1000,            // 2 minutes
  VOLUME: 30 * 1000,             // 30 seconds
  REVENUE: 10 * 1000,            // 10 seconds
  INFRASTRUCTURE: 60 * 60 * 1000, // 60 minutes (1 hour) ‚¨ÖÔ∏è LONG CACHE!
} as const;
```

**Why Infrastructure has 60-min cache:**
- Comment at line 38: "prevents constant refreshing & data inconsistency"
- Large dataset (4000+ accounts) = slow to fetch
- Data doesn't change frequently (nightly sync only)

**Context-Level Cache Check:** [DashboardContext.tsx:515-524](src/contexts/DashboardContext.tsx#L515-L524)
```typescript
// Check if we have recent data (< 10 minutes old) and skip refresh
const now = Date.now();
const lastUpdate = infrastructureDashboard.lastUpdated?.getTime() || 0;
const age = now - lastUpdate;
const TEN_MINUTES = 10 * 60 * 1000;

if (!force && age < TEN_MINUTES && infrastructureDashboard.emailAccounts.length > 0) {
  console.log(`[Infrastructure] Skipping fetch - data is only ${Math.round(age / 1000 / 60)} minutes old`);
  return; // Use existing cached data
}
```

**‚ö†Ô∏è Double Caching Issue:**
1. **Service-level cache:** 60 minutes (dataService.ts)
2. **Context-level skip:** 10 minutes (DashboardContext.tsx)
3. **Force refresh:** Clears both caches (line 610-612)

**Manual Refresh Implementation:**
```typescript
// When forcing refresh, clear cache first to ensure fresh data
if (force) {
  console.log('[Infrastructure] Forcing refresh - clearing cache first');
  clearDashboardCache('infrastructure');
}
```

### 6. Data Freshness Indicators

**UI shows data age:**
- Last updated timestamp
- Color-coded freshness (green < 6h, yellow < 24h, red > 24h)
- Next sync countdown (until midnight)

**Location:** [EmailAccountsPage.tsx:68-114](src/pages/EmailAccountsPage.tsx#L68-L114)

---

## Root Cause Analysis

### Why might totals be inaccurate?

| Issue | Impact | Likelihood | Severity |
|-------|--------|------------|----------|
| **Stale Cache (60 min)** | Dashboard shows old data until manual refresh | HIGH | MEDIUM |
| **Nightly Sync Only** | New accounts don't appear until next day | MEDIUM | LOW |
| **10,000 Row Limit** | If > 10k accounts, some are hidden | LOW | HIGH |
| **Browser Cache** | Old JavaScript/data in browser | MEDIUM | MEDIUM |
| **Deduplication Logic** | Same email+workspace from multiple instances | LOW | LOW |

### Most Likely Culprits:

1. **Stale Cache (60-minute TTL)**
   - User visits page ‚Üí data cached for 60 min
   - Changes happen in database ‚Üí user still sees old data
   - **Solution:** Click "Manual Refresh" button

2. **Nightly Sync Timing**
   - Polling job runs at midnight
   - New accounts added during day ‚Üí won't show until tomorrow
   - **Solution:** Expected behavior, document for users

3. **Browser Hard Refresh Needed**
   - Service worker or browser cache
   - **Solution:** Cmd+Shift+R (Mac) or Ctrl+Shift+R (Windows)

---

## Data Accuracy Checklist

To verify if displayed data is accurate:

### ‚úÖ Check 1: Is the data fresh?
```
Look at "Last Updated" timestamp on dashboard
- Green indicator (< 6h) = FRESH
- Yellow indicator (6-24h) = STALE
- Red indicator (> 24h) = VERY STALE
```

### ‚úÖ Check 2: Force refresh
```
Click "Manual Refresh" button on dashboard
Wait for data to reload
Check if totals changed
```

### ‚úÖ Check 3: Clear browser cache
```
1. Open DevTools (F12)
2. Go to Network tab
3. Check "Disable cache"
4. Hard reload (Cmd+Shift+R)
```

### ‚úÖ Check 4: Check console logs
```
Open browser console
Look for:
  "[Infrastructure Realtime] ‚úÖ Fetched X unique accounts in Yms"
  "[DEDUPLICATION COMPLETE] Removed X duplicates"
  "üìä Dashboard Stats Calculated: { totalAccounts: X, ... }"
```

### ‚úÖ Check 5: Verify database sync
```
Check polling_job_status table:
- job_name: 'poll-sender-emails'
- status: 'success' or 'failed'
- started_at: should be recent (< 24h)
```

---

## Recommendations

### üî• HIGH PRIORITY

1. **Reduce Infrastructure Cache TTL**
   - **Current:** 60 minutes
   - **Recommended:** 10-15 minutes
   - **File:** [dataService.ts:38](src/services/dataService.ts#L38)
   - **Reason:** 60 min is too long for "real-time" dashboard

2. **Add Cache Age Warning**
   - Show warning banner if data > 30 min old
   - "This data may be outdated - click Refresh for latest"
   - **File:** [EmailAccountsPage.tsx](src/pages/EmailAccountsPage.tsx)

3. **Remove 10,000 Row Limit**
   - **Current:** `.limit(totalCount || 10000)`
   - **Problem:** Silently truncates data if > 10k accounts
   - **Solution:** Use `.limit(totalCount)` only (remove fallback)
   - **File:** [realtimeDataService.ts:351](src/services/realtimeDataService.ts#L351)

### ‚ö° MEDIUM PRIORITY

4. **Add Real-Time Sync Status**
   - Show polling job status prominently
   - "Last synced: 2 hours ago ‚ö†Ô∏è"
   - "Next sync: in 22 hours"
   - **Already exists** but could be more prominent

5. **Improve Deduplication Logging**
   - Already logs to console: ‚úÖ
   - Consider surfacing to UI for transparency
   - "Showing 4,234 unique accounts (removed 123 duplicates)"

6. **Add Data Export Feature**
   - Allow exporting raw data to CSV
   - Users can verify totals independently
   - **Already exists** for zero-reply accounts - extend to all

### üí° LOW PRIORITY

7. **Add Automatic Refresh Option**
   - User toggle: "Auto-refresh every 15 min"
   - Disabled by default (current behavior)

8. **Add Client-Level Drill-Down**
   - Click client ‚Üí see all their accounts
   - Shows both connected & disconnected
   - **Already exists** as modal - improve discoverability

---

## Testing Plan

### Manual Testing Steps:

1. **Test Cache Behavior**
   ```
   1. Open dashboard
   2. Note total accounts shown
   3. Wait 5 minutes
   4. Hard refresh page ‚Üí should show SAME data (cached)
   5. Click "Manual Refresh" ‚Üí should fetch NEW data
   6. Check console logs for cache hits/misses
   ```

2. **Test Deduplication**
   ```
   1. Find a client with accounts in multiple bison instances
   2. Verify they're NOT double-counted
   3. Check console: "[DEDUPLICATION] Removed X duplicates"
   ```

3. **Test Calculations**
   ```
   1. Export data to CSV
   2. Count unique emails per workspace in Excel
   3. Compare to dashboard totals
   4. Should match exactly
   ```

4. **Test Data Freshness**
   ```
   1. Check "Last Updated" timestamp
   2. Verify it matches database last_synced_at
   3. Should be < 24 hours old (nightly sync)
   ```

---

## Console Logs to Monitor

When debugging, watch for these console messages:

### ‚úÖ Success Indicators:
```javascript
"üöÄüöÄüöÄ [REALTIME SERVICE] fetchInfrastructureDataRealtime() called!"
"[Infrastructure Realtime] Fetching from sender_emails_cache..."
"[Infrastructure Realtime] Found 4234 total accounts in cache"
"‚úÖ‚úÖ‚úÖ [DEDUPLICATION COMPLETE] Removed 123 duplicates (same email+workspace, different instance)"
"‚úÖ‚úÖ‚úÖ [FINAL COUNT] 4111 unique accounts"
"[Infrastructure Realtime] ‚úÖ Fetched 4111 unique accounts in 1234ms"
"üìä Dashboard Stats Calculated: { totalAccounts: 4111, uniqueClients: 93, ... }"
```

### ‚ö†Ô∏è Warning Indicators:
```javascript
"[Infrastructure Realtime] Data is 25.3 hours old - polling job may have failed"
"[Infrastructure] Using cached data (age: 45m, expires in: 15m)"
"‚ö†Ô∏è Bypassing validation temporarily for debugging"
```

### ‚ùå Error Indicators:
```javascript
"‚ùå [Infrastructure Realtime] Database error: ..."
"[Infrastructure] Fetch failed: ..."
"[Infrastructure] Returning stale cache due to fetch error"
```

---

## Conclusion

### Current State Assessment:

‚úÖ **Data Flow is Fundamentally Sound**
- Real-time database queries work correctly
- Deduplication logic is accurate (after recent fix)
- UI calculations are simple and correct

‚ö†Ô∏è **Potential Issues:**
1. **60-minute cache** may show stale data
2. **Nightly sync only** means new accounts have 24h lag
3. **10,000 row limit** could silently truncate large datasets

üîß **If Users Report Wrong Totals:**
1. Ask them to click "Manual Refresh"
2. Check browser console for errors
3. Verify polling job ran successfully
4. Check database row count vs displayed total
5. Clear browser cache and reload

### Next Steps:
1. Implement HIGH priority recommendations
2. Add more prominent cache age indicators
3. Consider reducing cache TTL to 15 minutes
4. Remove or increase 10,000 row limit
5. Add automated tests for calculation logic

---

## Appendix: Code References

### Key Functions:

1. **Data Fetching:**
   - [fetchInfrastructureDataRealtime()](src/services/realtimeDataService.ts#L331-L460)

2. **Transformation:**
   - [transformToEmailAccount()](src/lib/fieldMappings.ts#L176-L205)

3. **Deduplication:**
   - [Deduplication Logic](src/services/realtimeDataService.ts#L383-L405)

4. **UI Calculations:**
   - [Account Stats Calculation](src/pages/EmailAccountsPage.tsx#L822-L870)

5. **Dashboard Display:**
   - [Total Accounts Card](src/pages/EmailAccountsPage.tsx#L1073)
   - [Avg per Client Card](src/pages/EmailAccountsPage.tsx#L1089)

### Database Tables:

- **sender_emails_cache** - Main source of email account data
- **polling_job_status** - Tracks nightly sync job status

### Environment Variables:

Check [.env.local.example](.env.local.example) for:
- `VITE_SUPABASE_URL`
- `VITE_SUPABASE_ANON_KEY`

---

**Report Generated:** October 20, 2025
**Audit Duration:** 45 minutes
**Files Analyzed:** 6 core files + database schema
**Status:** ‚úÖ Audit Complete